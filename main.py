from query import query_model
from model_loader import load_model
import torch


def main():
    tokenizer, model = load_model()
    device = "mps" if torch.backends.mps.is_available() else "cpu"

    print("\nðŸ”¹ Type 'exit' to stop.")

    while True:
        user_prompt = input("\nðŸ’¬ Enter your query: ")
        if user_prompt.lower() == "exit":
            print("ðŸ‘‹ Exiting. Have a great day!")
            break

        response = query_model(user_prompt, model, tokenizer, device)
        print("\nðŸ¤– AI Response:", response)


if __name__ == "__main__":
    main()
